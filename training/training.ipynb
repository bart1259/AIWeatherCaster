{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in custom functions to make this class more focused on just\n",
    "# training models\n",
    "from utils import load_data, standardize, normalize, replace_nans, split_data, coord_to_index, preview_graph, get_metric_name, get_base_model_mse_loss, get_model_mse_loss, loss_by_metric, loss_by_pixel, distributed_loss\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.metrics import mean_squared_error\n",
    "from keras.layers import Input,Conv2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data\n",
    "data = load_data(\"../training_data/*.npy\")\n",
    "print(f\"\\nLoaded data shape: {data.shape}\")\n",
    "\n",
    "# If normalizing\n",
    "original_mins = np.nanmin(data, axis=(0,1,2))\n",
    "original_maxs = np.nanmax(data, axis=(0,1,2))\n",
    "\n",
    "# Preprocess Data\n",
    "print(\"normalize...\")\n",
    "data = normalize(data, wind_special=False)\n",
    "print(\"Replacing Nans...\")\n",
    "data = replace_nans(data)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data is normalized and in the expected shape\n",
    "print(original_mins)\n",
    "print(original_maxs)\n",
    "print(np.nanmin(data, axis=(0,1,2)))\n",
    "print(np.nanmax(data, axis=(0,1,2)))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,20))\n",
    "pos = plt.imshow(data[180,:,:,2], origin=\"lower\")\n",
    "plt.colorbar(pos)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Splitting data...\")\n",
    "(x_train_data, y_train_data, x_test_data, y_test_data) = split_data(data, 0.9, days=3, spacing=1)\n",
    "print(\"Data Split!\")\n",
    "# auto_encoder_x = data\n",
    "# auto_encoder_y = data\n",
    "\n",
    "y_train_data = y_train_data[:,0,:,:]\n",
    "y_test_data = y_test_data[:,0,:,:]\n",
    "\n",
    "print(x_train_data.shape)\n",
    "print(y_train_data.shape)\n",
    "print(x_test_data.shape)\n",
    "print(y_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condense(data):\n",
    "    (sample_count, seq_len, height, width, channels) = data.shape\n",
    "    data = data.transpose(0,2,3,1,4).reshape(sample_count, height, width, seq_len * channels)\n",
    "    return data\n",
    "\n",
    "print(x_train_data.shape)\n",
    "x_train_data = condense(x_train_data)\n",
    "print(x_train_data.shape)\n",
    "x_test_data = condense(x_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_positional_encoding(height, width, vec_count = 5):\n",
    "    \n",
    "    embedings = []\n",
    "    \n",
    "    for i in range(vec_count):\n",
    "        grid = np.array([np.arange(width) / (width - 1)] * height)\n",
    "        if i % 2 == 0:\n",
    "            w_1 = -np.cos(grid * math.pi * (1 + (i * 2)))\n",
    "        else:\n",
    "            w_1 = np.sin(grid * math.pi * (1 + (i * 2)))\n",
    "        w_1 = (w_1 / 2) + 0.5\n",
    "        embedings.append(w_1)\n",
    "        \n",
    "    for i in range(vec_count):\n",
    "        grid = np.array([np.arange(height) / (height - 1)] * width).T\n",
    "        if i % 2 == 0:\n",
    "            w_1 = -np.cos(grid * math.pi * (1 + (i * 2)))\n",
    "        else:\n",
    "            w_1 = np.sin(grid * math.pi * (1 + (i * 2)))\n",
    "        w_1 = (w_1 / 2) + 0.5\n",
    "        embedings.append(w_1)\n",
    "    \n",
    "    return np.array(embedings)\n",
    "\n",
    "def add_encoding(data, pe):\n",
    "    encoded_data = []\n",
    "    for i in range(len(data)):\n",
    "        element = data[i]\n",
    "        for i in range(len(pe) - 1, -1, -1):\n",
    "            element = np.insert(element, 0, pe[1], axis=2)\n",
    "\n",
    "        encoded_data.append(element)\n",
    "        \n",
    "    return np.array(encoded_data)\n",
    "\n",
    "\n",
    "# plt.imshow(gen_positional_encoding(48, 116)[9])\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "pe = gen_positional_encoding(48, 116)\n",
    "x_train_data = add_encoding(x_train_data, pe)\n",
    "x_test_data = add_encoding(x_test_data, pe)\n",
    "\n",
    "print(x_train_data.shape)\n",
    "print(x_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFeeder(keras.utils.Sequence) :    \n",
    "    def __init__(self, data_x, data_y, batch_size) :\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    \n",
    "    def __len__(self) :\n",
    "        return (np.ceil(self.data_x.shape[0] / float(self.batch_size))).astype(np.int)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx) :\n",
    "        batch_x = self.data_x[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        batch_y = self.data_y[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "\n",
    "        return np.array(batch_x), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = pd.read_csv(\"./mask.csv\", header=None)\n",
    "mask = mask.to_numpy()\n",
    "mask = np.stack([mask] * 8, axis=2)\n",
    "\n",
    "def custom_loss(yTrue,yPred):\n",
    "    if yTrue.shape[0] == None:\n",
    "        return mean_squared_error(yTrue, yPred)\n",
    "    msk = np.stack([mask] * yTrue.shape[0])\n",
    "    yPred = yPred * msk\n",
    "    return mean_squared_error(yTrue, yPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "gc.collect()\n",
    "try: \n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "def create_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(512, (1, 41), activation='sigmoid', padding=\"same\"))\n",
    "    model.add(Conv2D(512, (41, 1), activation='sigmoid', padding=\"same\"))\n",
    "    model.add(Conv2D(32,  (3, 3),  activation='sigmoid', padding=\"same\"))\n",
    "    model.add(Conv2D(512, (1, 9),  activation='sigmoid', padding=\"same\"))\n",
    "    model.add(Conv2D(512, (9, 1),  activation='sigmoid', padding=\"same\"))\n",
    "    model.add(Conv2D(32,  (3, 3),  activation='sigmoid', padding=\"same\"))\n",
    "    model.add(Conv2D(512, (1, 5),  activation='sigmoid', padding=\"same\"))\n",
    "    model.add(Conv2D(512, (5, 1),  activation='sigmoid', padding=\"same\"))\n",
    "    model.add(Conv2D(512, (3, 3),  activation='sigmoid', padding=\"same\"))\n",
    "    model.add(Conv2D(8,   (1, 1),  activation=None, padding=\"same\"))\n",
    "    \n",
    "    \n",
    "    opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "    model.compile(optimizer=opt,\n",
    "              loss=custom_loss,\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "print(\"Compiling...\")\n",
    "\n",
    "model = create_model()\n",
    "model.build([None, 48, 116, 34])\n",
    "model.load_weights(\"./models.h5\")\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=f\"./model.h5\", \n",
    "                         monitor='val_loss',\n",
    "                         verbose=1, \n",
    "                         save_best_only=True,\n",
    "                         mode='min')\n",
    "\n",
    "print(\"Fitting...\")\n",
    "model.fit(DataFeeder(x_train_data, y_train_data, BATCH_SIZE), \n",
    "          validation_data=DataFeeder(x_test_data, y_test_data, BATCH_SIZE), \n",
    "          callbacks=[checkpoint],\n",
    "          epochs = 100,\n",
    "          shuffle = True)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = x_test_data[0:1]\n",
    "test_output = model.predict(test_input)\n",
    "\n",
    "print(test_input.shape)\n",
    "print(test_output.shape)\n",
    "print(x_test_data.shape)\n",
    "print(y_test_data.shape)\n",
    "\n",
    "plt.figure(figsize=(40,20))\n",
    "pos = plt.imshow(test_output[0,:,:,2], origin=\"lower\")\n",
    "plt.colorbar(pos)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_loss = get_base_model_mse_loss(x_test_data[:,:,:,-8:], y_test_data)\n",
    "m_loss = get_model_mse_loss(model, x_test_data, y_test_data)\n",
    "\n",
    "print(f\"Base Model Loss {bm_loss}\")\n",
    "print(f\"Model Loss {m_loss}\")\n",
    "print(f\"{round(100 * (bm_loss - m_loss) / bm_loss, 2)}% better than baseline model\")\n",
    "\n",
    "losses_by_metric = loss_by_metric(model, x_test_data, y_test_data)\n",
    "for i in range(8):\n",
    "    print(f\"{get_metric_name(i)} Error : {math.sqrt(losses_by_metric[i]) * (original_maxs[i] - original_mins[i])}\")\n",
    "\n",
    "spatial_loss = loss_by_pixel(model, x_test_data, y_test_data)\n",
    "plt.figure(figsize=(40,20))\n",
    "pos = plt.imshow(spatial_loss, origin=\"lower\",  cmap=\"gray\")\n",
    "plt.colorbar(pos)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d13a778d1c417e59d6f5fc6a4afc9afc36c2e1cacb7abacd5e5162b98d2ec1d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
